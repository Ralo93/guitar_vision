{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f1f918b-b1a2-4c73-b89a-4247bcf18328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "class SmallDataset(Dataset):\n",
    "    \"\"\"A simple dataset for demonstration purposes.\"\"\"\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, label\n",
    "\n",
    "def load_model_from_hub(url, save_path):\n",
    "    \"\"\"\n",
    "    Load a model from TensorFlow Hub, save it locally, and return a PyTorch model.\n",
    "    \"\"\"\n",
    "    # Load the TensorFlow Hub model\n",
    "    model = hub.load(url)\n",
    "    \n",
    "    # Save the model locally\n",
    "    tf.saved_model.save(model, save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def inspect_model(model):\n",
    "    \"\"\"\n",
    "    Inspect the model's architecture and parameters.\n",
    "    \"\"\"\n",
    "    model.summary()  # This works for TensorFlow models\n",
    "    for layer in model.layers:\n",
    "        print(f\"Layer: {layer.name}, Output shape: {layer.output_shape}, Trainable: {layer.trainable}\")\n",
    "\n",
    "def convert_to_pytorch(model):\n",
    "    \"\"\"\n",
    "    Extract the core model architecture from TensorFlow Hub and use it in PyTorch.\n",
    "    \"\"\"\n",
    "    # Extract the feature layers from the TF model (remove final classification layer)\n",
    "    feature_extractor = model.signatures['serving_default']\n",
    "    \n",
    "    # Assuming we get embeddings as output, this would be the feature extractor\n",
    "    return feature_extractor\n",
    "\n",
    "class TransferLearningModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom PyTorch model for transfer learning.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_extractor, num_classes=13):\n",
    "        super(TransferLearningModel, self).__init__()\n",
    "        self.feature_extractor = feature_extractor  # Pre-trained feature extractor\n",
    "        self.fc = nn.Linear(1280, num_classes)  # Adjust this based on the output size of your extractor\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            # Extract features from the pre-trained model\n",
    "            features = self.feature_extractor(x)\n",
    "        # Pass through the new classification layer\n",
    "        x = self.fc(features)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a05d80b-4fe5-4022-bd19-73ece30132f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_parameters(model):\n",
    "    \"\"\"\n",
    "    Freeze all parameters in the feature extractor and only keep the final layer trainable.\n",
    "    \"\"\"\n",
    "    # Freeze all layers except the final fully connected layer\n",
    "    for param in model.feature_extractor.parameters():\n",
    "        param.requires_grad = False\n",
    "    print(\"All parameters frozen except the final layer.\")\n",
    "\n",
    "def train_model(model, dataloader, num_epochs=5, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Train the modified model on a very small dataset.\n",
    "    \"\"\"\n",
    "    # Use cross-entropy loss for classification\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Only optimize the final layer\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            # Move inputs and labels to GPU if available\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}\")\n",
    "    \n",
    "    print(\"Training complete.\")\n",
    "\n",
    "def prepare_dataloader(data, labels, batch_size=4):\n",
    "    \"\"\"\n",
    "    Prepare a DataLoader for the small dataset.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = SmallDataset(data, labels, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4f942-454c-4964-b90b-38990e79ed60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da67946-1772-4a02-99ca-f6853b543f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rapha\\repositories\\guitar_hero\\.envs\\dev_env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c02ac3e0-26e8-42fa-8b41-1effdc0a1719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16000)\n"
     ]
    }
   ],
   "source": [
    "# Define model input\n",
    "input_waveform = tf.keras.Input(shape=(16000,), dtype=tf.float32, name='waveform')\n",
    "print(input_waveform.shape)\n",
    "\n",
    "save_path = r'C:\\Users\\rapha\\repositories\\guitar_hero\\vggish_model\\saved_model.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f49a9522-0113-450e-805c-be838ddb0e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'keras_layer_1' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None, 96, 64), dtype=float32, sparse=False, name=input_features>,) and kwargs: {} for signature: (waveform: TensorSpec(shape=(None,), dtype=tf.float32, name=None)).\n\nCall arguments received by layer 'keras_layer_1' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None, 96, 64), dtype=float32, sparse=False, name=input_features>\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m input_features \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m64\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m vggish_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mvggish_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39minput_features, outputs\u001b[38;5;241m=\u001b[39mvggish_outputs)\n",
      "File \u001b[1;32m~\\repositories\\guitar_hero\\.envs\\dev_env\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\repositories\\guitar_hero\\.envs\\dev_env\\Lib\\site-packages\\tensorflow_hub\\keras_layer.py:242\u001b[0m, in \u001b[0;36mKerasLayer.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# ...but we may also have to pass a Python boolean for `training`, which\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# is the logical \"and\" of this layer's trainability and what the surrounding\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# model is doing (analogous to keras.layers.BatchNormalization in TF2).\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# For the latter, we have to look in two places: the `training` argument,\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_training_argument:\n\u001b[1;32m--> 242\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable:\n",
      "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling layer 'keras_layer_1' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None, 96, 64), dtype=float32, sparse=False, name=input_features>,) and kwargs: {} for signature: (waveform: TensorSpec(shape=(None,), dtype=tf.float32, name=None)).\n\nCall arguments received by layer 'keras_layer_1' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None, 96, 64), dtype=float32, sparse=False, name=input_features>\n  • training=None"
     ]
    }
   ],
   "source": [
    "vggish_layer = hub.KerasLayer('https://tfhub.dev/google/vggish/1', trainable=False)\n",
    "print(\"ok\")\n",
    "input_waveform = tf.keras.Input(shape=(16000,), dtype=tf.float32, name='waveform')\n",
    "print(\"ok2\")\n",
    "vggish_outputs = vggish_layer(input_features)\n",
    "print(\"ok3\")\n",
    "model = tf.keras.Model(inputs=input_features, outputs=vggish_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf033b19-21dd-43b1-b82f-2bf3511afe57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File format not supported: filepath=C:\\Users\\rapha\\repositories\\guitar_hero\\vggish_model\\saved_model.pb. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(C:\\Users\\rapha\\repositories\\guitar_hero\\vggish_model\\saved_model.pb, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKerasLayer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKerasLayer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel successfully loaded from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32m~\\repositories\\guitar_hero\\.envs\\dev_env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy H5 format files (`.h5` extension). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that the legacy SavedModel format is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported by `load_model()` in Keras 3. In \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder to reload a TensorFlow SavedModel as an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference-only layer in Keras 3, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.layers.TFSMLayer(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, call_endpoint=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(note that your `call_endpoint` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: File format not supported: filepath=C:\\Users\\rapha\\repositories\\guitar_hero\\vggish_model\\saved_model.pb. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(C:\\Users\\rapha\\repositories\\guitar_hero\\vggish_model\\saved_model.pb, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(save_path, custom_objects={'KerasLayer': hub.KerasLayer})\n",
    "print(f\"Model successfully loaded from {save_path}\")\n",
    "loaded_model.summary()\n",
    "return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a9ac60-05e5-402c-ac92-4c46d01c50ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the pre-trained TensorFlow model from hub\n",
    "#tf_model = load_model_from_hub('https://tfhub.dev/google/vggish/1', save_path='./vggish_model')\n",
    "\n",
    "# Load the pre-trained TensorFlow model from disk\n",
    "\n",
    "# Convert to PyTorch compatible model\n",
    "pytorch_model = convert_to_pytorch(tf_model)\n",
    "\n",
    "# Create a PyTorch transfer learning model\n",
    "model = TransferLearningModel(pytorch_model, num_classes=13)\n",
    "\n",
    "# Freeze the feature extractor layers\n",
    "freeze_parameters(model)\n",
    "\n",
    "# Prepare a small dataset for training\n",
    "data = [...]  # Your data here (could be images, spectrograms, etc.)\n",
    "labels = [...]  # Corresponding labels\n",
    "dataloader = prepare_dataloader(data, labels, batch_size=4)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec51856-8979-4847-8331-bcc460e506e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799aa1c0-7db4-4656-aa0f-0785422da62f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python guitar_hero",
   "language": "python",
   "name": "guitar_hero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
